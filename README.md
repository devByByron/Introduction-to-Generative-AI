# Introduction-to-Generative-AI

## ✍️ Key Learnings & Notes

**Overview**

**Define generative AI**

**Explain how generative AI works**

**Describe generative AI model types**

**Describe generative AI applications** 


**Generative AI**

A type of AI that can create content (e.g., text, images, audio, synthetic data). Creates new content based on what it has learning from existing content.

Different from AI in general and from machine learning, which is a subfield of AI.

**Artificial Intelligence (AI)**

Branch of computer science that makes intelligent agents able to reason, learn, and act autonomously.

Goal: machines that think and act like humans.

**Machine Learning (ML)**

A method in AI where models are trained on data to predict outcomes for new, unseen data.

Enables computers to learn without being explicitly programmed.


**Supervised vs Unsupervised Machine Learning**
**1. Supervised Learning**

Data: Uses labeled data (each input has a known output/label).

Goal: Learn from past examples to predict future outcomes.

Example:

A restaurant predicts tip amount based on bill total and order type (pickup or delivery).

Process:

Model is trained with input data (X) and correct answers (Y).

Compares its predictions to the actual labels.

Adjusts to reduce error (difference between predicted and actual values).

**2. Unsupervised Learning**

Data: Uses unlabeled data (no pre-assigned answers).

Goal: Discover patterns or groups in the data.

Example:

Group employees by tenure and income to see who might be on a fast track.

Process:

Looks for natural clusters or groupings in the data without being told what’s correct.

Key Difference

Supervised → “I know the correct answers; teach me to predict them.”

Unsupervised → “I don’t know the answers; find patterns for me.”



**Machine Learning vs Deep Learning**

Machine Learning (ML) → Broad field with many techniques.

Deep Learning (DL) → A type of ML that uses artificial neural networks (ANNs) to process more complex patterns.

Artificial Neural Networks → Inspired by the brain, made of interconnected “neurons” that process data and make predictions.

Deep Learning Models → Have many layers of neurons, allowing them to learn more complex patterns than traditional ML.

Semi-supervised learning → Uses a small amount of labeled data + a large amount of unlabeled data to train models.

**Generative AI in the AI hierarchy**

Generative AI (Gen AI) → Subset of deep learning.

Can use supervised, unsupervised, or semi-supervised learning.

Large Language Models (LLMs) → Also a subset of deep learning.

Generative vs Discriminative Models

Discriminative models

Classify or predict labels for data points.

Learn P(y | x) → probability of output y given input x.

Example: Identify a picture as a dog or cat.

Generative models

Learn P(x, y) → joint probability of input and output.

Can generate new data/content based on learned patterns.

Example: After learning about dogs, generate a new image of a dog.

**Key takeaway**

Discriminative → “Tell me what this is.” (classification)

Generative → “Make me a new one.” (creation)

How to Tell if It's Generative AI
Not Generative AI

Output (Y) is:

A number (e.g., predicted sales)

A class/label (e.g., spam or not spam)

A probability

Example: “Is this email spam?” → Output: Yes/No

Generative AI

Output (Y) is:

Natural language (text, speech)

Images, audio, video, code

Example: “Write me an email” → Output: Full text generated

Uses foundation models trained on massive datasets (labeled + unlabeled) across many data types.

**Math View**

Formula: 
𝑦=𝑓(𝑥)
y=f(x)

x = inputs (data: CSV, text, audio, images)

f = model function

y = output

If 
𝑦
y is predictive → not Gen AI.

If 
𝑦
y is creative content → Gen AI.

Evolution of AI

Traditional programming → Hard-code rules (e.g., “If it has 4 legs and fur, it’s a cat”).

Neural networks → Learn to classify (“Is this a cat?” → Yes/No).

Generative AI → Create entirely new content (“Generate a picture or description of a cat”).


**Transformers and Generative AI**

Transformers revolutionized natural language processing in 2018.

They consist of an encoder (processes input) and a decoder (generates output).

Hallucinations in Transformers

Hallucinations are nonsensical or incorrect outputs generated by the model.

Causes include:

Insufficient training data.

Noisy or low-quality data.

Lack of context.

Inadequate constraints.

Problems caused by hallucinations:

Output can be confusing or misleading.

Prompts and Prompt Design

A prompt is a short text input given to a large language model (LLM) to guide its output.

Prompt design is the process of crafting effective prompts to achieve desired results.

Training Data Dependence

Generative AI learns patterns and structures from its training data.

With a browser-based prompt interface, users can generate their own content.

Google Cloud Tools

**Vertex AI Studio**

Enables quick exploration and customization of generative AI models on Google Cloud.

Provides pre-trained models, fine-tuning tools, deployment options, and a community forum.

**Vertex AI**

Built for users with little or no coding experience.

Supports creation of chatbots, digital assistants, custom search engines, and knowledge bases.

No prior machine learning knowledge required.

**Gemini**

Multi-modal AI model that can analyze images, audio, and programming code.

More versatile than traditional language models.

Advanced architecture supports complex tasks and wide adaptability.

Continuously updated in the Model Garden.
